{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats vs Dogs Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is my implementation on the popular Kaggle \"Cats vs Dogs\" challenge. The plan is to use transfer learning for this problem. Since the PC is pretty old (GeForce 960, Intel i5 5600, 8GB DDR4) I decided to use MobileNet V2 for this task. I expected the training to be relatively fast with this model but I still had to leave it running a few hours for each test. The end result was surprisingly good to me - 98.1% accuracy. I was wondering what could be the result with Inception Resnet v2 and I achieved about 98.6% accuracy without any tweaking of parameters or intermediate layer unfreezing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, decode_predictions, preprocess_input\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Input, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img, load_img\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before I start I resized the images to the MobileNet required size (224, 224) pixels. This way I save a lot of time on batch loading. My PC allows only 4 image batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = os.path.join(os.getcwd(), \"train\")\n",
    "# os.mkdir(\"small_images\")\n",
    "dataset_dir = os.path.join(os.getcwd(), 'small_images')\n",
    "cats_dir = os.path.join(dataset_dir, 'cats')\n",
    "dogs_dir = os.path.join(dataset_dir, 'dogs')\n",
    "\n",
    "# for pic in os.listdir(source):\n",
    "#     img = os.path.join(source, pic)\n",
    "#     img = Image.open(img)\n",
    "#     img = img.resize([224, 224], Image.ANTIALIAS)\n",
    "#     img.save(os.path.join(dataset_dir, pic), format=\"JPEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here I'm getting the filenames from the cats and dogs subdirectories. After that It's easy to get the labels. I'm using \"0\" for cats and \"1\" for dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for dirname, subdir, file in os.walk(dataset_dir)]\n",
    "files = files[1:]\n",
    "\n",
    "filenames = []\n",
    "for f in files[0]:\n",
    "    filenames.append(os.path.join(cats_dir, f))\n",
    "for f in files[1]:\n",
    "    filenames.append(os.path.join(dogs_dir, f))\n",
    "    \n",
    "labels = [name.split(\".\")[-3][-3:] for name in filenames]\n",
    "labels = [tf.constant(0) if label == \"cat\" else tf.constant(1) for label in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here I'm shuffling the data using pandas because it's very fast and easy. Shuffling using tf.data.Dataset on such a large dataset was very slow and I found this solution much better. After that I'm manually splitting the data to training, validation and test sets (23000 / 1000 / 1000). Since the I have such a large dataset I can test on more images and thus have the chance to predict some very hard pictures as we'll see in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"filenames\": filenames, \"labels\": labels})\n",
    "df = df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "shuffled_fnames = [path for path in df.filenames]\n",
    "shuffled_labels = [label for label in df.labels]\n",
    "\n",
    "train_filenames, val_filenames, test_filenames = shuffled_fnames[:23000], shuffled_fnames[23000:24000], shuffled_fnames[24000:]\n",
    "train_labels, val_labels, test_labels = shuffled_labels[:23000], shuffled_labels[23000:24000], shuffled_labels[24000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_function(filename, label):\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_image(img)\n",
    "    img /= 255\n",
    "    return (img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_filenames, train_labels))\n",
    "train_dataset = train_dataset.map(map_function)\n",
    "train_dataset = train_dataset.batch(4)\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_filenames, val_labels))\n",
    "val_dataset = val_dataset.map(map_function)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_filenames, test_labels))\n",
    "test_dataset = test_dataset.map(map_function)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking MobilenetV2's predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I'm visualizing the model's predictions just to be more familiar with it. It's perfect for the task because it's been trained on lots of varieties of animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnet_full = MobileNetV2(input_shape=(224, 224, 3))\n",
    "mnet_full.compile(optimizer=Adam(), loss=binary_crossentropy, metrics=[binary_accuracy])\n",
    "predictions = mnet_full.predict_generator(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose what picture of the train dataset to predict\n",
    "num = 2\n",
    "img = load_img(test_filenames[num])\n",
    "plt.imshow(img)\n",
    "prediction = predictions[num]\n",
    "prediction = np.expand_dims(prediction, 0)\n",
    "decode_predictions(prediction, top=5)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading MobileNetV2 body for transfer learning and freezing all layers. I'm doing this to manually add my dense layers for the binary classification and to train only the dense layers parameters using the pre-trained convolution layers as feature extractors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnet = MobileNetV2(include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in mnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 62720)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8028288   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 10,286,913\n",
      "Trainable params: 8,028,673\n",
      "Non-trainable params: 2,258,240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    mnet,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-5), loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(os.getcwd(), 'logs')\n",
    "checkpoint_dir = os.path.join(os.getcwd(), 'chpt{epoch}')\n",
    "checkpoint = ModelCheckpoint(checkpoint_dir, save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir=log_dir)\n",
    "learn_rate = ReduceLROnPlateau(factor=0.2, patience=3, min_lr=1e-6, cooldown=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.localtime()\n",
    "\n",
    "history = model.fit_generator(train_dataset, \n",
    "                    steps_per_epoch=len(train_filenames)//BATCH_SIZE, \n",
    "                    epochs=25, \n",
    "                    validation_data=val_dataset, \n",
    "                    validation_steps=len(val_filenames)//BATCH_SIZE,\n",
    "                    callbacks=[tensorboard, learn_rate, checkpoint]\n",
    "                    )\n",
    "\n",
    "end = time.localtime()\n",
    "total_minutes = end.tm_min - start.tm_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(end)\n",
    "print(start)\n",
    "print(f\"Total time elapsed: {end.tm_hour - start.tm_hour}:{abs(end.tm_min - start.tm_min)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats_dogs_transfer_mobilenet_dataset.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = load_model(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('cats_dogs_transfer_mobilenet_dataset.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.evaluate_generator(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The graph shows that epoch 8 was the optimal one for stop training. I didn't have a checkpoint there and the moment was skipped, but since I plan to fine-tune the model this should be corected. In the future I'd use checkpoint save on every epoch if 1 epoch takes 30 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = loaded_model.predict_generator(test_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on a chosen set of 10 pictures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the test dir has 1000 images\n",
    "from_index = 990 \n",
    "to_index = 1000\n",
    "for i in range(from_index, to_index):\n",
    "    path = test_filenames[i]\n",
    "    img = load_img(path)\n",
    "    plt.imshow(img)\n",
    "    img = map_function(test_filenames[i], test_labels[i])[0]\n",
    "    img = np.expand_dims(img, 0)\n",
    "    pred = loaded_model.predict(img)\n",
    "    if pred > 0.5:\n",
    "        result = \"dog\"\n",
    "    else:\n",
    "        result = \"cat\"\n",
    "    plt.title(f'prediction: {result}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I'm unfreezing 8 more layers for additional training. The goal is to have the last convolutional layers extract smaller features and thus fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in loaded_model.layers[0].layers[-8:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(optimizer=Adam(lr=1e-5), loss='binary_crossentropy', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.localtime()\n",
    "\n",
    "history1 = new_model.fit_generator(train_dataset, \n",
    "                    steps_per_epoch=len(train_filenames)//BATCH_SIZE, \n",
    "                    epochs=8, \n",
    "                    validation_data=val_dataset, \n",
    "                    validation_steps=len(val_filenames)//BATCH_SIZE,\n",
    "                    callbacks=[tensorboard, learn_rate, checkpoint]\n",
    "                    )\n",
    "\n",
    "end = time.localtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.evaluate_generator(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.save('cats_dogs_transfer_mobilenet_dataset_finetuned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('cats_dogs_transfer_mobilenet_dataset_finetuned.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This was a middle step to and now I'm unfreezing all layers to fine-tune the model for the last time. It's a bit slower because we have about 700k more parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.layers[0].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model = new_model\n",
    "fine_tuned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model.compile(optimizer=Adam(lr=1e-5), loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "checkpoint_dir = os.path.join(os.getcwd(), 'checkpoint-{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_dir, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start2 = time.time()\n",
    "\n",
    "history2 = fine_tuned_model.fit_generator(train_dataset, \n",
    "                    steps_per_epoch=len(train_filenames)//BATCH_SIZE, \n",
    "                    epochs=10, \n",
    "                    validation_data=val_dataset, \n",
    "                    validation_steps=len(val_filenames)//BATCH_SIZE,\n",
    "                    callbacks=[tensorboard, checkpoint, learn_rate]\n",
    "                    )\n",
    "\n",
    "end2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total time elapsed: {end2 - start2} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model.save('cats_dogs_transfer_mobilenet_dataset_finetuned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model = load_model('cats_dogs_transfer_mobilenet_dataset_finetuned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model.save_weights('./checkpoint/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./checkpoint/my_checkpoint')\n",
    "fine_tuned_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06740164769489775, 0.981]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuned_model.evaluate_generator(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now comes the most interesting part. I'm testing the model on the 1000 images test dataset and after that I'm plotting the wrong predictions. This way we can visually try to find out why the model was wrong. It turns out the \"hard\" pictures have a lot of objects, the animal is partially visible, or the quality is very bad. I can safely say that if the picture is relatively good and the object is not partially hidden we can be confidet that the prediction will be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the test dir has 1000 images\n",
    "wrong_preds = []\n",
    "for i in range(1000):\n",
    "    img, label = map_function(test_filenames[i], test_labels[i])\n",
    "    img = np.expand_dims(img, 0)\n",
    "    pred = fine_tuned_model.predict(img)\n",
    "    if pred >= 0.5:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "#     plt.title(f'prediction: {result}')\n",
    "#     plt.show()\n",
    "    if result != int(label.numpy()):\n",
    "        wrong_preds.append(test_filenames[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrong_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in wrong_preds:\n",
    "    plt.figure()\n",
    "    path = i\n",
    "    pic = load_img(path)\n",
    "    plt.imshow(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on a different image placed in the current working directory\n",
    "name = 'cat.jpg'\n",
    "img = tf.io.read_file(os.path.join(os.getcwd(), name))\n",
    "img = tf.image.decode_jpeg(img, channels=3)\n",
    "plt.imshow(img)\n",
    "img = tf.cast(img, tf.float32)\n",
    "img = tf.image.resize(img, [224, 224])\n",
    "img = np.expand_dims(img, 0)\n",
    "pred = fine_tuned_model.predict(img)\n",
    "if pred > 0.5:\n",
    "    result = \"Dog\"\n",
    "else:\n",
    "    result = \"Cat\"\n",
    "plt.title(f'prediction:  {result},  probability:  {(100-pred[0][0]*100):.2f} %')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MobileNet is a great model in terms of performance and results. It can be used in video applications where a few % accuracy can be sacrificed for the great performance. \n",
    "#### There is little more that can be done to increase the accuracy. I tried to augument the pictures but the dataset is so large that I didn't notice any difference. I could probably adjust the dropout and add L1/L2 regularizers but I felt like I have reached optimal results without this. After all If I need higher accuracy I can switch to Inception Resnet but I decided to learn how to solve new deep learning problems than to waste time in training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'cat.jpg'\n",
    "img = tf.io.read_file(os.path.join(os.getcwd(), name))\n",
    "img = tf.image.decode_jpeg(img, channels=3)\n",
    "img = tf.cast(img, tf.float32)\n",
    "img = tf.image.resize(img, [224, 224])\n",
    "img = np.expand_dims(img, 0)\n",
    "immg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
